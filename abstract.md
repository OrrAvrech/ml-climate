# Multimodal Learning Framework for Dense Prediction Remote Sensing Tasks

## TLDR
Use multiple modalities (Sentinel-1, Sentinel-2, Elevation, Location, etc.) and a combination of SSL techniques suitable for each group of modalities to provide a general framework for dense prediction tasks in remote sensing.

## Motivation
Self-supervised learning can be particularly valuable for dense prediction tasks, especially given the high cost associated with gathering segmentation masks and bounding box annotations for remote sensing data.
The idea is to provide a general framework for building feature extractors with localization that work well on downstream remote sensing prediction tasks.

## Data

## References
- [ClimaX](https://s3.us-east-1.amazonaws.com/climate-change-ai/papers/iclr2023/35/paper.pdf)
- [Lightweight, Pre-trained Transformers for Remote Sensing Timeseries](https://arxiv.org/pdf/2304.14065.pdf)
- [TIML - Task Informed Meta Learning](https://openreview.net/pdf?id=de0KufElojN)
- [Multimodal contrastive learning for remote sensing tasks](https://arxiv.org/pdf/2209.02329.pdf)
- [SSL Cookbook](https://arxiv.org/pdf/2304.12210.pdf)
